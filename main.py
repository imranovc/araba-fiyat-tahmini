# -*- coding: utf-8 -*-
"""arac_fiyat_tahmin

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NZNx_Qihazb9swzErMGX_S4vKi4zQ4Wh
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv('turkey_car_market.csv')

df.info()

df.head()

eksik_data = df.isnull().sum()
toplam_yüzde = (eksik_data.sum()/df.shape[0])*100
print(f'Eksik veri yüzdesi: %{toplam_yüzde}')

print("İçerisinde Bilmiyorum İfadesi Olan Özellikler")
özellikler = df.columns
for i in özellikler:
    print(i, len(df.loc[df[i] == "Bilmiyorum"]))
print("*******************************************\nİçerisinde - İfadesi Olan Özellikler")
özellikler = df.columns
for i in özellikler:
    print(i, len(df.loc[df[i] == "-"]))

df.drop('Beygir Gucu',axis=1, inplace=True)
df.head()

x = df.loc[df["CCM"] == "Bilmiyorum"]
y=x.index
y

df.drop('CCM',axis=1,inplace=True)
df.head()

print("İçerisinde Bilmiyorum İfadesi Olan Özellikler")
özellikler = df.columns
for i in özellikler:
    print(i, len(df.loc[df[i] == "Bilmiyorum"]))
print("*******************************************\nİçerisinde - İfadesi Olan Özellikler")
özellikler = df.columns
for i in özellikler:
    print(i, len(df.loc[df[i] == "-"]))

df.shape

q1 = df["Fiyat"].quantile(0.25)
q3 = df["Fiyat"].quantile(0.75)

IQC = q3 - q1

alt_sınır = q1 - 1.5*IQC
üst_sınır = q3 + 1.5*IQC

print("alt_sınır: "+str(alt_sınır))
print("üst_sınır: "+str(üst_sınır))

aykırı = (df["Fiyat"] < alt_sınır) | (df["Fiyat"] > üst_sınır)
aykırı_veri=df[aykırı]
ayk=aykırı_veri.index
ayk

df.drop(ayk, axis=0, inplace=True)
df.head()

a=df["Fiyat"].max()
b=df["Fiyat"].min()
print(f'En yüksek Fiyat: {a}')
print(f'En düşük Fiyat: {b}')

fig, ax = plt.subplots()
sns.barplot(x = df["Yakıt Turu"], y = df["Fiyat"])

plt.style.use("ggplot")
fig, ax = plt.subplots(figsize=(25, 10))
sns.barplot(x = df["Marka"], y = df["Fiyat"])

fig, ax = plt.subplots()
sns.barplot(x = df["Kimden"], y = df["Fiyat"])

df.drop('İlan Tarihi',axis=1, inplace=True)
df.head()

dummy_Yakıt_Turu = pd.get_dummies(df["Yakıt Turu"])
dummy_Vites = pd.get_dummies(df["Vites"])
dummy_Kimden = pd.get_dummies(df["Kimden"])
dummy_Durum = pd.get_dummies(df["Durum"])

new_df = df.copy()
new_df = pd.concat([new_df, dummy_Yakıt_Turu, dummy_Vites, dummy_Kimden, dummy_Durum], axis=1)
new_df.drop(["Yakıt Turu", "Vites", "Kimden","Durum"], axis = 1, inplace=True)
new_df.head()

car_veri = new_df.drop(["Fiyat"],axis=1)

Fiyat = new_df["Fiyat"]

car_veri["Fiyat"] = Fiyat

car_veri.head()

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
columns=['Marka', 'Arac Tip Grubu', 'Arac Tip', 'Renk', 'Kasa Tipi']

for i in columns:

    car_veri[i] = le.fit_transform(car_veri[i])

car_veri.head()

y=car_veri['Fiyat']
X=car_veri.drop(columns=["Fiyat"])

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.25, random_state=42)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.datasets import make_regression



# Modeli varsayılan hiperparametrelerle eğitme
lr_default = LinearRegression()
model_default = lr_default.fit(X_train, y_train)
y_pred_default = model_default.predict(X_test)

# Modelin doğruluk metriklerini hesaplama
mse_default = mean_squared_error(y_test, y_pred_default)
mae_default = mean_absolute_error(y_test, y_pred_default)
r2_default = r2_score(y_test, y_pred_default)

# GridSearchCV ile hiperparametre optimizasyonu
# LinearRegression için hiperparametre yok, ama örnek olması için farklı parametreler kullanabiliriz
param_grid = {
    'fit_intercept': [True, False],  # 'fit_intercept' parametresinin farklı değerlerini deneyebiliriz
}

# GridSearchCV kullanarak en iyi modeli bulma
grid_search = GridSearchCV(LinearRegression(), param_grid, cv=5, scoring='neg_mean_squared_error')
grid_search.fit(X_train, y_train)

# En iyi modeli ve tahminleri elde etme
best_model = grid_search.best_estimator_
y_pred_best = best_model.predict(X_test)

# En iyi modelin doğruluk metriklerini hesaplama
mse_best = mean_squared_error(y_test, y_pred_best)
mae_best = mean_absolute_error(y_test, y_pred_best)
r2_best = r2_score(y_test, y_pred_best)

# Sonuçları yazdırma
print("Varsayılan Model Sonuçları:")
print(f"Ortalama Kare Hatası (MSE): {mse_default}")
print(f"Ortalama Mutlak Hata (MAE): {mae_default}")
print(f"R^2 Skoru: {r2_default}")

print("\nEn İyi Model Sonuçları (GridSearchCV):")
print(f"Ortalama Kare Hatası (MSE): {mse_best}")
print(f"Ortalama Mutlak Hata (MAE): {mae_best}")
print(f"R^2 Skoru: {r2_best}")

# Gerçek ve tahmin edilen değerler için görseller
plt.figure(figsize=(14, 7))

# Varsayılan Model
plt.subplot(1, 2, 1)
plt.scatter(y_test, y_pred_default, color='blue', label="Tahminler (Varsayılan)")
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2, label="Doğru Sonuçlar")
plt.title("Varsayılan Model: Gerçek vs Tahmin Edilen")
plt.xlabel("Gerçek Değerler")
plt.ylabel("Tahmin Edilen Değerler")
plt.legend()

# En İyi Model (GridSearchCV)
plt.subplot(1, 2, 2)
plt.scatter(y_test, y_pred_best, color='green', label="Tahminler (En İyi Model)")
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2, label="Doğru Sonuçlar")
plt.title("En İyi Model (GridSearchCV): Gerçek vs Tahmin Edilen")
plt.xlabel("Gerçek Değerler")
plt.ylabel("Tahmin Edilen Değerler")
plt.legend()

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.tree import DecisionTreeRegressor
from sklearn.datasets import make_regression



# Karar Ağacı modelini varsayılan hiperparametrelerle eğitme
dt_default = DecisionTreeRegressor(random_state=42)
dt_model_default = dt_default.fit(X_train, y_train)
y_pred_dt_default = dt_model_default.predict(X_test)

# Varsayılan modelin doğruluk metriklerini hesaplama
mse_dt_default = mean_squared_error(y_test, y_pred_dt_default)
mae_dt_default = mean_absolute_error(y_test, y_pred_dt_default)
r2_dt_default = r2_score(y_test, y_pred_dt_default)

# GridSearchCV ile hiperparametre optimizasyonu
param_grid_dt = {
    'max_depth': [3, 5, 7, None],  # Ağaç derinliğini farklı seviyelerde deniyoruz
    'min_samples_split': [2, 5, 10],  # Bölünme için minimum örnek sayısını değiştiriyoruz
    'min_samples_leaf': [1, 2, 4],  # Yapraklarda minimum örnek sayısını değiştiriyoruz
}

# GridSearchCV kullanarak en iyi modeli bulma
grid_search_dt = GridSearchCV(DecisionTreeRegressor(random_state=42), param_grid_dt, cv=5, scoring='neg_mean_squared_error')
grid_search_dt.fit(X_train, y_train)

# En iyi modeli ve tahminleri elde etme
best_model_dt = grid_search_dt.best_estimator_
y_pred_dt_best = best_model_dt.predict(X_test)

# En iyi modelin doğruluk metriklerini hesaplama
mse_dt_best = mean_squared_error(y_test, y_pred_dt_best)
mae_dt_best = mean_absolute_error(y_test, y_pred_dt_best)
r2_dt_best = r2_score(y_test, y_pred_dt_best)

# Sonuçları yazdırma
print("Varsayılan Karar Ağacı Modeli Sonuçları:")
print(f"Ortalama Kare Hatası (MSE): {mse_dt_default}")
print(f"Ortalama Mutlak Hata (MAE): {mae_dt_default}")
print(f"R^2 Skoru: {r2_dt_default}")

print("\nEn İyi Karar Ağacı Modeli Sonuçları (GridSearchCV):")
print(f"Ortalama Kare Hatası (MSE): {mse_dt_best}")
print(f"Ortalama Mutlak Hata (MAE): {mae_dt_best}")
print(f"R^2 Skoru: {r2_dt_best}")

# Gerçek ve tahmin edilen değerler için görseller
plt.figure(figsize=(14, 7))

# Varsayılan Model
plt.subplot(1, 2, 1)
plt.scatter(y_test, y_pred_dt_default, color='blue', label="Tahminler (Varsayılan)")
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2, label="Doğru Sonuçlar")
plt.title("Varsayılan Model: Gerçek vs Tahmin Edilen")
plt.xlabel("Gerçek Değerler")
plt.ylabel("Tahmin Edilen Değerler")
plt.legend()

# En İyi Model (GridSearchCV)
plt.subplot(1, 2, 2)
plt.scatter(y_test, y_pred_dt_best, color='green', label="Tahminler (En İyi Model)")
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2, label="Doğru Sonuçlar")
plt.title("En İyi Model (GridSearchCV): Gerçek vs Tahmin Edilen")
plt.xlabel("Gerçek Değerler")
plt.ylabel("Tahmin Edilen Değerler")
plt.legend()

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.ensemble import AdaBoostRegressor
from sklearn.datasets import make_regression



# AdaBoost modelini varsayılan hiperparametrelerle eğitme
adaboost_default = AdaBoostRegressor(random_state=42)
adaboost_model_default = adaboost_default.fit(X_train, y_train)
y_pred_adaboost_default = adaboost_model_default.predict(X_test)

# Varsayılan modelin doğruluk metriklerini hesaplama
mse_adaboost_default = mean_squared_error(y_test, y_pred_adaboost_default)
mae_adaboost_default = mean_absolute_error(y_test, y_pred_adaboost_default)
r2_adaboost_default = r2_score(y_test, y_pred_adaboost_default)

# GridSearchCV ile hiperparametre optimizasyonu
param_grid_adaboost = {
    'n_estimators': [50, 100, 200],  # Öğrenme sayısını farklı seviyelerde deneyebiliriz
    'learning_rate': [0.01, 0.1, 0.5, 1],  # Öğrenme oranını farklı seviyelerde deneyebiliriz
}

# GridSearchCV kullanarak en iyi modeli bulma
grid_search_adaboost = GridSearchCV(AdaBoostRegressor(random_state=42), param_grid_adaboost, cv=5, scoring='neg_mean_squared_error')
grid_search_adaboost.fit(X_train, y_train)

# En iyi modeli ve tahminleri elde etme
best_model_adaboost = grid_search_adaboost.best_estimator_
y_pred_adaboost_best = best_model_adaboost.predict(X_test)

# En iyi modelin doğruluk metriklerini hesaplama
mse_adaboost_best = mean_squared_error(y_test, y_pred_adaboost_best)
mae_adaboost_best = mean_absolute_error(y_test, y_pred_adaboost_best)
r2_adaboost_best = r2_score(y_test, y_pred_adaboost_best)

# Sonuçları yazdırma
print("Varsayılan AdaBoost Modeli Sonuçları:")
print(f"Ortalama Kare Hatası (MSE): {mse_adaboost_default}")
print(f"Ortalama Mutlak Hata (MAE): {mae_adaboost_default}")
print(f"R^2 Skoru: {r2_adaboost_default}")

print("\nEn İyi AdaBoost Modeli Sonuçları (GridSearchCV):")
print(f"Ortalama Kare Hatası (MSE): {mse_adaboost_best}")
print(f"Ortalama Mutlak Hata (MAE): {mae_adaboost_best}")
print(f"R^2 Skoru: {r2_adaboost_best}")

# Gerçek ve tahmin edilen değerler için görseller
plt.figure(figsize=(14, 7))

# Varsayılan Model
plt.subplot(1, 2, 1)
plt.scatter(y_test, y_pred_adaboost_default, color='blue', label="Tahminler (Varsayılan)")
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2, label="Doğru Sonuçlar")
plt.title("Varsayılan Model: Gerçek vs Tahmin Edilen")
plt.xlabel("Gerçek Değerler")
plt.ylabel("Tahmin Edilen Değerler")
plt.legend()

# En İyi Model (GridSearchCV)
plt.subplot(1, 2, 2)
plt.scatter(y_test, y_pred_adaboost_best, color='green', label="Tahminler (En İyi Model)")
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2, label="Doğru Sonuçlar")
plt.title("En İyi Model (GridSearchCV): Gerçek vs Tahmin Edilen")
plt.xlabel("Gerçek Değerler")
plt.ylabel("Tahmin Edilen Değerler")
plt.legend()

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.datasets import make_regression



# Varsayılan modelin doğruluk metriklerini hesaplama
mse_rf_default = mean_squared_error(y_test, y_pred_rf_default)
mae_rf_default = mean_absolute_error(y_test, y_pred_rf_default)
r2_rf_default = r2_score(y_test, y_pred_rf_default)

# GridSearchCV ile hiperparametre optimizasyonu
param_grid_rf = {
    'n_estimators': [100],  # Ağaç sayısını farklı seviyelerde deneyebiliriz
    'max_depth': [50,100,],  # Ağaç derinliğini farklı seviyelerde deneyebiliriz
    'min_samples_split': [5,10],  # Bölünme için minimum örnek sayısını değiştiriyoruz
    'min_samples_leaf': [5,10],  # Yapraklarda minimum örnek sayısını değiştiriyoruz
}

# GridSearchCV kullanarak en iyi modeli bulma
grid_search_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=5, scoring='neg_mean_squared_error')
grid_search_rf.fit(X_train, y_train)

# En iyi modeli ve tahminleri elde etme
best_model_rf = grid_search_rf.best_estimator_
y_pred_rf_best = best_model_rf.predict(X_test)

# En iyi modelin doğruluk metriklerini hesaplama
mse_rf_best = mean_squared_error(y_test, y_pred_rf_best)
mae_rf_best = mean_absolute_error(y_test, y_pred_rf_best)
r2_rf_best = r2_score(y_test, y_pred_rf_best)

print("Varsayılan Random Forest Modeli Sonuçları:")
print(f"Ortalama Kare Hatası (MSE): {mse_rf_default}")
print(f"Ortalama Mutlak Hata (MAE): {mae_rf_default}")
print(f"R^2 Skoru: {r2_rf_default}")

print("\nEn İyi Random Forest Modeli Sonuçları (GridSearchCV):")
print(f"Ortalama Kare Hatası (MSE): {mse_rf_best}")
print(f"Ortalama Mutlak Hata (MAE): {mae_rf_best}")
print(f"R^2 Skoru: {r2_rf_best}")



# Gerçek ve tahmin edilen değerler için görseller
plt.figure(figsize=(14, 7))

plt.subplot(1, 2, 1)
plt.scatter(y_test, y_pred_rf_default, color='blue', label="Tahminler (Varsayılan)")
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2, label="Doğru Sonuçlar")
plt.title("Varsayılan Model: Gerçek vs Tahmin Edilen")
plt.xlabel("Gerçek Değerler")
plt.ylabel("Tahmin Edilen Değerler")
plt.legend()


# En İyi Model (GridSearchCV)
plt.subplot(1, 2, 2)
plt.scatter(y_test, y_pred_rf_best, color='green', label="Tahminler (En İyi Model)")
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2, label="Doğru Sonuçlar")
plt.title("En İyi Model (GridSearchCV): Gerçek vs Tahmin Edilen")
plt.xlabel("Gerçek Değerler")
plt.ylabel("Tahmin Edilen Değerler")
plt.legend()



plt.tight_layout()
plt.show()